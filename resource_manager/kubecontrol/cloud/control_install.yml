---
- hosts: cloudcontroller
  become: true
  tasks:
    - name: Configure node ip
      lineinfile:
        path: /etc/default/kubelet
        line: KUBELET_EXTRA_ARGS=--node-ip={{ cloud_ip }}
        create: true

    - name: Restart kubelet
      service:
        name: kubelet
        daemon_reload: true
        state: restarted

    - name: Forward IPv4 and let iptables see bridged traffic
      shell: |
        cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf
        overlay
        br_netfilter
        EOF

        sudo modprobe overlay
        sudo modprobe br_netfilter

        cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
        net.bridge.bridge-nf-call-iptables  = 1
        net.bridge.bridge-nf-call-ip6tables = 1
        net.ipv4.ip_forward                 = 1
        EOF

        sudo sysctl --system

    # - name: Create patches directory for Kubernetes
    #   command: mkdir /home/{{ username }}/patches

    # - name: Create kube-apiserver patch file
    #   shell: |
    #     cat > "/home/{{ username }}/patches/kube-apiserver.yaml" <<EOF
    #     spec:
    #       containers:
    #       - name: kube-apiserver
    #         resources:
    #           requests:
    #             cpu: 250m
    #             memory: 500Mi
    #           limits:
    #             cpu: 250m
    #             memory: 500Mi
    #     EOF

    # - name: Create kube-controller-manager patch file
    #   shell: |
    #     cat > "/home/{{ username }}/patches/kube-controller-manager.yaml" <<EOF
    #     spec:
    #       containers:
    #       - name: kube-controller-manager
    #         resources:
    #           requests:
    #             cpu: 100m
    #             memory: 200Mi
    #           limits:
    #             cpu: 100m
    #             memory: 200Mi
    #     EOF

    # - name: Create kube-scheduler patch file
    #   shell: |
    #     cat > "/home/{{ username }}/patches/kube-scheduler.yaml" <<EOF
    #     spec:
    #       containers:
    #       - name: kube-scheduler
    #         resources:
    #           requests:
    #             cpu: 100m
    #             memory: 200Mi
    #           limits:
    #             cpu: 100m
    #             memory: 200Mi
    #     EOF

    # - name: Create etcd patch file
    #   shell: |
    #     cat > "/home/{{ username }}/patches/etcd.yaml" <<EOF
    #     spec:
    #       containers:
    #       - name: etcd
    #         resources:
    #           requests:
    #             cpu: 200m
    #             memory: 400Mi
    #           limits:
    #             cpu: 200m
    #             memory: 400Mi
    #     EOF

    - name: Create kubelet config file
      shell: |
        cat > "/home/{{ username }}/config.yaml" <<EOF
        apiVersion: kubeadm.k8s.io/v1beta3
        kind: InitConfiguration
        localAPIEndpoint:
          advertiseAddress: {{ cloud_ip }}
        ---
        apiVersion: kubeadm.k8s.io/v1beta3
        kind: ClusterConfiguration
        apiServer:
          certSANs:
          - {{ cloud_ip }}
        imageRepository: {{ registry_ip }}
        kubernetesVersion: {{ kubeversion }}
        networking:
          podSubnet: 10.244.0.0/16
        ---
        apiVersion: kubelet.config.k8s.io/v1beta1
        kind: KubeletConfiguration
        containerLogMaxSize: "100Mi"
        containerLogMaxFiles: 10
        EOF
    # ---- From InitConfiguration
    # patches:
    #   directory: /home/{{ username }}/patches/
    #
    # ---- From ClusterConfiguration
    # controllerManager:
    #   extraArgs:
    #     kube-api-qps: "100000"
    #     kube-api-burst: "100000"
    # scheduler:
    #   extraArgs:
    #     kube-api-qps: "100000"
    #     kube-api-burst: "100000"
    #
    # ---- From KubeletConfiguration
    # maxPods: 265
    # eventRecordQPS: 0
    # kubeAPIQPS: 0
    # serializeImagePulls: false
    # maxParallelImagePulls: 10000
    # registryPullQPS: 0
    # featureGates:
    #   EventedPLEG: true

    - name: Initialize the Kubernetes cluster using kubeadm
      command: >
        kubeadm init
          --node-name {{ ansible_hostname }}
          --ignore-preflight-errors all
          --config /home/{{ username }}/config.yaml

    - name: Create user Kubernetes directory
      file:
        path: /home/{{ username }}/.kube
        state: directory

    - name: Copy Kubernetes files to user
      copy:
        src: /etc/kubernetes/admin.conf
        dest: /home/{{ username }}/.kube/config
        owner: "{{ username }}"
        group: "{{ username }}"
        remote_src: true

    - name: Set KUBECONFIG variable globally
      shell: echo "export KUBECONFIG=/home/{{ username }}/.kube/config" >> /etc/environment

    - name: Enable networking with Calico, only for cloud mode
      shell: |
        if [ "{{ cloud_mode }}" -gt "0" ]; then
          kubectl create -f /kube-flannel.yml
        fi

    - name: Create join command for worker nodes (cloud-only)
      shell: |
        echo '#!/bin/bash' > /tmp/join-command.txt
        kubeadm token create --print-join-command >> /tmp/join-command.txt

    - name: Copy join command to local file
      fetch:
        src: /tmp/join-command.txt
        dest: "{{ continuum_home }}/"
        flat: true

    - name: Remove unneeded Kubernetes join command file
      file:
        path: "{{ item }}"
        state: absent
      with_items:
        - /tmp/join-command.txt

    - name: Install Kata
      shell: |
        wget https://github.com/kata-containers/kata-containers/releases/download/3.1.3/kata-static-3.1.3-x86_64.tar.xz
        xzcat kata-static-3.1.3-x86_64.tar.xz | sudo tar -xvf - -C /

        sudo ln -s /opt/kata/bin/kata-runtime /usr/local/bin
        sudo ln -s /opt/kata/bin/containerd-shim-kata-v2 /usr/local/bin

        rm kata-static-3.1.3-x86_64.tar.xz

        sudo mkdir -p /var/lib/containerd/io.containerd.snapshotter.v1.devmapper

        sudo touch /var/lib/containerd/io.containerd.snapshotter.v1.devmapper/data
        sudo truncate -s 1G /var/lib/containerd/io.containerd.snapshotter.v1.devmapper/data

        sudo touch /var/lib/containerd/io.containerd.snapshotter.v1.devmapper/meta
        sudo truncate -s 1G /var/lib/containerd/io.containerd.snapshotter.v1.devmapper/meta

        DATA_DEV=$(sudo losetup --find --show /var/lib/containerd/io.containerd.snapshotter.v1.devmapper/data)
        META_DEV=$(sudo losetup --find --show /var/lib/containerd/io.containerd.snapshotter.v1.devmapper/meta)

        DATA_SIZE="$(sudo blockdev --getsize64 -q ${DATA_DEV})"
        LENGTH_IN_SECTORS=$((DATA_SIZE / 512))

        sudo dmsetup create devpool --table "0 ${LENGTH_IN_SECTORS} thin-pool ${META_DEV} ${DATA_DEV} 128 32768"

        file_path='/etc/containerd/config.toml'

        line_number=$(grep -n 'io.containerd.snapshotter.v1.devmapper' "$file_path" | cut -d ":" -f 1)

        sudo sed -i "$((line_number + 1)) c\    pool_name = \"devpool\"" "$file_path"
        sudo sed -i "$((line_number + 2)) c\    root_path = \"/var/lib/containerd/io.containerd.snapshotter.v1.devmapper\"" "$file_path"
        sudo sed -i "$((line_number + 3)) c\    base_image_size = \"1GB\"" "$file_path"
        sudo sed -i "$((line_number + 4)) c\    discard_blocks = true" "$file_path"

        sudo sed -i 's/snapshotter = "overlayfs"/snapshotter = "devmapper"/g' "$file_path"

        sudo systemctl restart containerd

        echo '#!/bin/bash' | sudo tee -a /usr/local/bin/containerd-shim-kata-fc-v2 > /dev/null
        echo 'KATA_CONF_FILE=/opt/kata/share/defaults/kata-containers/configuration-fc.toml /opt/kata/bin/containerd-shim-kata-v2 $@' | sudo tee -a /usr/local/bin/containerd-shim-kata-fc-v2 > /dev/null

        sudo chmod +x /usr/local/bin/containerd-shim-kata-fc-v2

        line_number=$(grep -n 'containerd.runtimes]' "$file_path" | cut -d ":" -f 1)

        sed -i "$((line_number + 1)) a\         [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.kata-fc]" "$file_path"
        sed -i "$((line_number + 2)) a\           runtime_type = \"io.containerd.kata-fc.v2\"\n" "$file_path"

        sudo systemctl restart containerd
